{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install patchify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install Keras-Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install segmentation-models-3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras \n",
    "print(tf.__version__)\n",
    "print(keras.__version__)\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make sure the GPU is available. \n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1: Data Preparation\n",
    "- Load dataset and slice padding\n",
    "- patchify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import io\n",
    "import os\n",
    "\n",
    "import random\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full Train 32 cases: train 24, val 8\n",
    "train_cases = ['Normal_03.tif','Normal_04.tif','Normal_05.tif','Normal_06.tif','Normal_07.tif','Normal_08.tif',\n",
    "               'Mild_03.tif','Mild_04.tif','Mild_05.tif','Mild_06.tif','Mild_07.tif','Mild_08.tif',\n",
    "               'Moderate_03.tif','Moderate_04.tif','Moderate_05.tif','Moderate_06.tif','Moderate_07.tif','Moderate_08.tif',\n",
    "               'Severe_02.tif','Severe_03.tif','Severe_04.tif','Severe_05.tif','Severe_06.tif','Severe_08.tif']\n",
    "\n",
    "# aug_cases = ['Normal_03.tif','Normal_07.tif',\n",
    "#              'Mild_03.tif','Mild_04.tif',\n",
    "#              'Moderate_03.tif','Moderate_04.tif',\n",
    "#              'Severe_02.tif','Severe_04.tif']\n",
    "\n",
    "#aug แบบ2 : แย่กว่าแบบ 1\n",
    "# aug_cases = ['Normal_03.tif','Normal_07.tif',\n",
    "#              'Mild_03.tif','Mild_08.tif',\n",
    "#              'Moderate_03.tif','Moderate_04.tif',\n",
    "#              'Severe_02.tif','Severe_04.tif']\n",
    "\n",
    "#aug แบบ3\n",
    "# aug_cases = ['Normal_07.tif',\n",
    "#              'Mild_08.tif',\n",
    "#              'Moderate_04.tif',\n",
    "#              'Severe_04.tif']\n",
    "\n",
    "val_cases = ['Normal_01.tif','Normal_02.tif',\n",
    "             'Mild_01.tif','Mild_02.tif',\n",
    "             'Moderate_01.tif','Moderate_02.tif',\n",
    "             'Severe_01.tif','Severe_07.tif']\n",
    "\n",
    "print('Train: ',len(train_cases))\n",
    "# print('Augment: ',len(aug_cases))\n",
    "print('Val:   ',len(val_cases))\n",
    "print('Total: ',(len(train_cases)+len(val_cases)))\n",
    "print(len(val_cases)/(len(train_cases)+len(val_cases)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Padding function\n",
    "def padding(image, slice_vol):\n",
    "    slice_, row, col= image.shape #(0,1,2) ตรงกับ (119,256,256)\n",
    "  \n",
    "    #เพิ่ม slice เข้าไป\n",
    "    if slice_vol > slice_: \n",
    "        slice_padding = slice_vol - slice_\n",
    "        padding_array = np.zeros((slice_padding, row, col))\n",
    "        image_paded = np.concatenate((image,padding_array), axis=0)\n",
    "    #เ  อา slice ออก\n",
    "    else: \n",
    "        image_paded = image[:slice_vol,:,:]\n",
    "    return np.asarray(np.array(image_paded), dtype=\"uint8\" )\n",
    "\n",
    "#Load data for loop function\n",
    "def load_data(list_case, drive_path,img_path,mask_path):\n",
    "    image = np.array([])\n",
    "    mask = np.array([])\n",
    " \n",
    "    for case in list_case:\n",
    "        img = io.imread(drive_path+img_path+'/'+case)\n",
    "        mask_ = io.imread(drive_path+mask_path+'/'+case)\n",
    "        print('image: '+case+' slice: ',img.shape[0])\n",
    "        print('mask:'+case+' slice: ',mask_.shape[0])\n",
    "        if image.shape[0] == 0:\n",
    "            if img.shape[0] <= 128:\n",
    "                image = padding(img, 128)\n",
    "                mask = padding(mask_, 128)\n",
    "            elif ((img.shape[0] > 128) and (img.shape[0] <= 175)):\n",
    "                # set center range \n",
    "                start_lung = int((img.shape[0]/2)-64)\n",
    "                end_lung = int((img.shape[0]/2)+64)\n",
    "                image = np.asarray(np.array(img[start_lung:end_lung,:,:]), dtype=\"uint8\" )\n",
    "                mask = np.asarray(np.array(mask_[start_lung:end_lung,:,:]), dtype=\"uint8\" )\n",
    "            else:\n",
    "                if img.shape[0] <= 256:\n",
    "                    # skipping slice\n",
    "                    image = padding(img[::2,:,:], 128)\n",
    "                    mask = padding(mask_[::2,:,:], 128)\n",
    "                else:\n",
    "                    print('CT slice volume is to large')\n",
    "          \n",
    "        else:\n",
    "            if img.shape[0] <= 128:\n",
    "                image = np.concatenate((image, padding(img, 128)), axis=0)\n",
    "                mask = np.concatenate((mask, padding(mask_, 128)), axis=0)\n",
    "            elif ((img.shape[0] > 128) and (img.shape[0] <= 175)):\n",
    "                # set center range \n",
    "                start_lung = int((img.shape[0]/2)-64)\n",
    "                end_lung = int((img.shape[0]/2)+64)\n",
    "                img_arr = np.asarray(np.array(img[start_lung:end_lung,:,:]), dtype=\"uint8\" )\n",
    "                mask_arr = np.asarray(np.array(mask_[start_lung:end_lung,:,:]), dtype=\"uint8\" )\n",
    "                image = np.concatenate((image, img_arr), axis=0)\n",
    "                mask = np.concatenate((mask, mask_arr), axis=0)\n",
    "            else:\n",
    "                if img.shape[0] <= 256:\n",
    "                    image = np.concatenate((image, padding(img[::2,:,:], 128)), axis=0)\n",
    "                    mask = np.concatenate((mask, padding(mask_[::2,:,:], 128)), axis=0)\n",
    "                else:\n",
    "                    print('CT slice volume is to large')\n",
    "   \n",
    "    print(image.shape)\n",
    "    print(mask.shape)\n",
    "    return image, mask\n",
    "\n",
    "#Load data for loop function and data augmentation\n",
    "def rotate_img(volume, angle):\n",
    "    augmented_volume = np.array([])\n",
    "    for i in range(volume.shape[0]):\n",
    "        if augmented_volume.shape[0] == 0:\n",
    "            augmented_volume = ndimage.rotate(volume[i], angle, reshape=False) #scipy_rotate(volume[i], angle)\n",
    "            augmented_volume = np.expand_dims(augmented_volume, axis=0)\n",
    "            # print('shape:', augmented_volume.shape)\n",
    "        else:\n",
    "            img_aug = ndimage.rotate(volume[i], angle, reshape=False) #scipy_rotate(volume[i], angle)\n",
    "            img_aug = np.expand_dims(img_aug, axis=0)\n",
    "            augmented_volume = np.concatenate((augmented_volume, img_aug), axis=0)\n",
    "            # print('shape:', augmented_volume.shape)\n",
    "    return augmented_volume\n",
    "\n",
    "def rotate_mask(mask_volume, angle):\n",
    "    augmented_volume = np.array([])\n",
    "    for i in range(mask_volume.shape[0]):\n",
    "        if augmented_volume.shape[0] == 0:\n",
    "            augmented_volume = ndimage.rotate(mask_volume[i], angle, order=0,reshape=False) #scipy_rotate(volume[i], angle)\n",
    "            augmented_volume = np.expand_dims(augmented_volume, axis=0)\n",
    "            # print('shape:', augmented_volume.shape)\n",
    "        else:\n",
    "            img_aug = ndimage.rotate(mask_volume[i], angle, order=0,reshape=False) #scipy_rotate(volume[i], angle)\n",
    "            img_aug = np.expand_dims(img_aug, axis=0)\n",
    "            augmented_volume = np.concatenate((augmented_volume, img_aug), axis=0)\n",
    "            # print('shape:', augmented_volume.shape)\n",
    "    return augmented_volume\n",
    "\n",
    "def load_data_aug(list_case, drive_path,img_path,mask_path):\n",
    "    image = np.array([])\n",
    "    mask = np.array([])\n",
    "    random.seed(20)\n",
    "    # define some rotation angles\n",
    "    angles = [-15, 15]\n",
    " \n",
    "    for case in list_case:\n",
    "        img = io.imread(drive_path+img_path+'/'+case)\n",
    "        mask_ = io.imread(drive_path+mask_path+'/'+case)\n",
    "        print('image: '+case+' slice: ',img.shape[0])\n",
    "        print('mask:'+case+' slice: ',mask_.shape[0])\n",
    "\n",
    "        # pick angles at random\n",
    "        angle = random.choice(angles)\n",
    "        print(case+' angle: ',angle)\n",
    "\n",
    "        if image.shape[0] == 0:\n",
    "            # augmentation\n",
    "            img = rotate_img(img, angle)\n",
    "            mask_ = rotate_mask(mask_, angle)\n",
    "\n",
    "            # slice volumn adjust\n",
    "            if img.shape[0] <= 128:\n",
    "                image = padding(img, 128)\n",
    "                mask = padding(mask_, 128)\n",
    "            elif ((img.shape[0] > 128) and (img.shape[0] <= 175)):\n",
    "                # set center range \n",
    "                start_lung = int((img.shape[0]/2)-64)\n",
    "                end_lung = int((img.shape[0]/2)+64)\n",
    "                image = np.asarray(np.array(img[start_lung:end_lung,:,:]), dtype=\"uint8\" )\n",
    "                mask = np.asarray(np.array(mask_[start_lung:end_lung,:,:]), dtype=\"uint8\" )\n",
    "            else:\n",
    "                if img.shape[0] <= 256:\n",
    "                    # skipping slice\n",
    "                    image = padding(img[::2,:,:], 128)\n",
    "                    mask = padding(mask_[::2,:,:], 128)\n",
    "                else:\n",
    "                    print('CT slice volume is to large')\n",
    "          \n",
    "        else:\n",
    "            # augmentation\n",
    "            img = rotate_img(img, angle)\n",
    "            mask_ = rotate_mask(mask_, angle)\n",
    "\n",
    "            # slice volumn adjust\n",
    "            if img.shape[0] <= 128:\n",
    "                image = np.concatenate((image, padding(img, 128)), axis=0)\n",
    "                mask = np.concatenate((mask, padding(mask_, 128)), axis=0)\n",
    "            elif ((img.shape[0] > 128) and (img.shape[0] <= 175)):\n",
    "                # set center range \n",
    "                start_lung = int((img.shape[0]/2)-64)\n",
    "                end_lung = int((img.shape[0]/2)+64)\n",
    "                img_arr = np.asarray(np.array(img[start_lung:end_lung,:,:]), dtype=\"uint8\" )\n",
    "                mask_arr = np.asarray(np.array(mask_[start_lung:end_lung,:,:]), dtype=\"uint8\" )\n",
    "                image = np.concatenate((image, img_arr), axis=0)\n",
    "                mask = np.concatenate((mask, mask_arr), axis=0)\n",
    "            else:\n",
    "                if img.shape[0] <= 256:\n",
    "                    image = np.concatenate((image, padding(img[::2,:,:], 128)), axis=0)\n",
    "                    mask = np.concatenate((mask, padding(mask_[::2,:,:], 128)), axis=0)\n",
    "                else:\n",
    "                    print('CT slice volume is to large')\n",
    "   \n",
    "    print(image.shape)\n",
    "    print(mask.shape)\n",
    "    return image, mask\n",
    "\n",
    "def load_dataStartEndLung(list_case, drive_path,img_path,mask_path):\n",
    "    image = np.array([])\n",
    "    mask = np.array([])\n",
    " \n",
    "    for case in list_case:\n",
    "        img = io.imread(drive_path+img_path+'/'+case)\n",
    "        mask_ = io.imread(drive_path+mask_path+'/'+case)\n",
    "        print('image: '+case+' slice: ',img.shape[0])\n",
    "        print('mask:'+case+' slice: ',mask_.shape[0])\n",
    "        if image.shape[0] == 0:\n",
    "            if img.shape[0] <= 128:\n",
    "                image = padding(img, 128)\n",
    "                mask = padding(mask_, 128)\n",
    "            else:\n",
    "                if img.shape[0] <= 256:\n",
    "                    # skipping slice\n",
    "                    image = padding(img[::2,:,:], 128)\n",
    "                    mask = padding(mask_[::2,:,:], 128)\n",
    "                else:\n",
    "                    print('CT slice volume is to large')\n",
    "          \n",
    "        else:\n",
    "            if img.shape[0] <= 128:\n",
    "                image = np.concatenate((image, padding(img, 128)), axis=0)\n",
    "                mask = np.concatenate((mask, padding(mask_, 128)), axis=0)\n",
    "            else:\n",
    "                if img.shape[0] <= 256:\n",
    "                    image = np.concatenate((image, padding(img[::2,:,:], 128)), axis=0)\n",
    "                    mask = np.concatenate((mask, padding(mask_[::2,:,:], 128)), axis=0)\n",
    "                else:\n",
    "                    print('CT slice volume is to large')\n",
    "   \n",
    "    print(image.shape)\n",
    "    print(mask.shape)\n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Tiff_folder = 'Tif_256x256/'\n",
    "# Tiff_folder = 'Tif_512x512/'\n",
    "# Tiff_folder ='Tif_256x256_StartEnd/'\n",
    "img_path_c1 = 'images'\n",
    "img_path_c2 = 'images_createCLAHE'\n",
    "img_path_c3 = 'images_equalizeHist'\n",
    "mask_path = 'masks'\n",
    "\n",
    "path_ = '/tf/Project/LungLobe/'\n",
    "drive_path = path_+Tiff_folder\n",
    "drive_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# image, mask = load_data(train_cases, drive_path,img_path_c1, mask_path)\n",
    "cre, mask = load_data(train_cases, drive_path,img_path_c2, mask_path)\n",
    "# equ, mask = load_data(train_cases, drive_path,img_path_c3, mask_path)\n",
    "\n",
    "# image, mask = load_dataStartEndLung(train_cases, drive_path,img_path,mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data augmentation\n",
    "# image_aug, mask_aug = load_data_aug(aug_cases, drive_path,img_path,mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.unique(mask_aug))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_img, test_mask = load_data(val_cases, drive_path,img_path_c1,mask_path)\n",
    "test_cre, test_mask = load_data(val_cases, drive_path,img_path_c2,mask_path)\n",
    "# test_equ, test_mask = load_data(val_cases, drive_path,img_path_c3,mask_path)\n",
    "\n",
    "# test_img, test_mask = load_dataStartEndLung(val_cases, drive_path,img_path,mask_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.unique(cre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change image value to [0,1]\n",
    "# image = image/255\n",
    "# test_img = test_img/255\n",
    "\n",
    "# cre = cre/255\n",
    "# test_cre = test_cre/255\n",
    "\n",
    "# equ = equ/255\n",
    "# test_equ = test_equ/255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.unique(test_cre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.unique(mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Slice visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "slice plot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_slices(num_rows, num_columns, width, height, data):\n",
    "    \"\"\"Plot a montage of 20 CT slices\"\"\"\n",
    "    # data = np.rot90(np.array(data))\n",
    "    # data = np.transpose(data)\n",
    "    data = np.reshape(np.array(data), (num_rows, num_columns, width, height))\n",
    "    rows_data, columns_data = data.shape[0], data.shape[1]\n",
    "    heights = [slc[0].shape[0] for slc in data]\n",
    "    widths = [slc.shape[1] for slc in data[0]]\n",
    "    fig_width = 20.0\n",
    "    fig_height = fig_width * sum(heights) / sum(widths)\n",
    "    f, axarr = plt.subplots(\n",
    "        rows_data,\n",
    "        columns_data,\n",
    "        figsize=(fig_width, fig_height),\n",
    "        gridspec_kw={\"height_ratios\": heights},\n",
    "    )\n",
    "    for i in range(rows_data):\n",
    "        for j in range(columns_data):\n",
    "            axarr[i, j].imshow(data[i][j], cmap=\"gray\")\n",
    "            axarr[i, j].axis(\"off\")\n",
    "    plt.subplots_adjust(wspace=0, hspace=0, left=0, right=1, bottom=0, top=1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Visualize raw images\n",
    "# plot_slices(10, 15, 256, 256, test_cre[:150, :, :]) #image, cre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mask of the CT scan.\n",
    "# plot_slices(20, 20, 256, 256, mask[:400, :, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patchify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from patchify import patchify, unpatchify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Train image:',image.shape)\n",
    "print('Train image:',cre.shape)\n",
    "# print('Train image:',equ.shape)\n",
    "print('Train mask:',mask.shape)\n",
    "# print('Augmented image:',image_aug.shape)\n",
    "# print('Augmented mask:',mask_aug.shape)\n",
    "\n",
    "# image = np.concatenate((image, image_aug), axis=0)\n",
    "# mask = np.concatenate((mask, mask_aug), axis=0)\n",
    "# print(image.shape)\n",
    "# print(mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#z,x,y for model (128, 256, 256) Densenet121, resnet18\n",
    "slice_volumn = 128 # set จำนวนสไลด์ที่จะใช้เทรน\n",
    "'''\n",
    "Train\n",
    "'''\n",
    "# img_patches = patchify(image, (slice_volumn, 256, 256), step=slice_volumn)\n",
    "img_patches = patchify(cre, (slice_volumn, 256, 256), step=slice_volumn)\n",
    "# img_patches = patchify(equ, (slice_volumn, 256, 256), step=slice_volumn)\n",
    "mask_patches = patchify(mask, (slice_volumn, 256, 256), step=slice_volumn)\n",
    "\n",
    "'''\n",
    "Test\n",
    "'''\n",
    "# test_img_patches = patchify(test_img, (slice_volumn, 256, 256), step=slice_volumn)\n",
    "test_img_patches = patchify(test_cre, (slice_volumn, 256, 256), step=slice_volumn)\n",
    "# test_img_patches = patchify(test_equ, (slice_volumn, 256, 256), step=slice_volumn)\n",
    "test_mask_patches = patchify(test_mask, (slice_volumn, 256, 256), step=slice_volumn)\n",
    "\n",
    "print(img_patches.shape)\n",
    "print(mask_patches.shape)\n",
    "print(test_img_patches.shape)\n",
    "print(test_mask_patches.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = np.reshape(img_patches, (-1, img_patches.shape[3], img_patches.shape[4], img_patches.shape[5]))\n",
    "input_mask = np.reshape(mask_patches, (-1, mask_patches.shape[3], mask_patches.shape[4], mask_patches.shape[5]))\n",
    "\n",
    "input_test_img = np.reshape(test_img_patches, (-1, test_img_patches.shape[3], test_img_patches.shape[4], test_img_patches.shape[5]))\n",
    "input_test_mask = np.reshape(test_mask_patches, (-1, test_mask_patches.shape[3], test_mask_patches.shape[4], test_mask_patches.shape[5]))\n",
    "\n",
    "print(input_img.shape)  # n_patches, x, y, z\n",
    "print(input_test_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Channels\n",
    "# train_img = np.stack((input_img,input_img_CLAHE,input_img_equalizeHist), axis=-1)\n",
    "train_img = np.stack((input_img,)*3, axis=-1)\n",
    "train_mask = np.expand_dims(input_mask, axis=4)\n",
    "\n",
    "# img_test = np.stack((input_test_img,input_test_img_CLAHE,input_test_img_equalizeHist), axis=-1)\n",
    "img_test = np.stack((input_test_img,)*3, axis=-1)\n",
    "mask_test = np.expand_dims(input_test_mask, axis=4)\n",
    "\n",
    "print(train_img.shape)\n",
    "print(train_mask.shape)\n",
    "print(img_test.shape)\n",
    "print(mask_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "n_classes = 6\n",
    "\n",
    "y_train = to_categorical(train_mask, num_classes=n_classes)\n",
    "y_test = to_categorical(mask_test, num_classes=n_classes)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_img\n",
    "X_test = img_test\n",
    "# y_train = train_mask_cat\n",
    "# y_test = test_mask_cat\n",
    "\n",
    "# raw image\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "# mask\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 2: Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3Dunet-Densenet121, 3DFPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import segmentation_models_3D as sm\n",
    "# from segmentation_models.losses import CategoricalCELoss\n",
    "\n",
    "encoder_weights = 'imagenet'\n",
    "\n",
    "#Try densenet121, densenet169, densenet201 Total params: 22ล้าน\n",
    "# resnet18, resnet34, resnet50, resnet101, resnet152\n",
    "#inceptionv3, efficientnetb0\n",
    "BACKBONE = 'resnet152'\n",
    "activation = 'softmax'\n",
    "patch_size = 256 # 128, 224, 256, 512\n",
    "volumn_size = slice_volumn # 32, 64, 128\n",
    "n_classes = 6\n",
    "channels=3\n",
    "\n",
    "LR = 0.0001\n",
    "optim = keras.optimizers.Adam(LR)\n",
    "\n",
    "metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n",
    "preprocess_input = sm.get_preprocessing(BACKBONE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prep = preprocess_input(X_train)\n",
    "X_test_prep = preprocess_input(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.Unet(BACKBONE, classes=n_classes, \n",
    "                input_shape=(volumn_size, patch_size, patch_size, channels), \n",
    "                encoder_weights=encoder_weights,\n",
    "                #encoder_freeze = True, # set เพื่อทำการ Tuning\n",
    "                activation=activation,\n",
    "                dropout=0.2)\n",
    "# model = sm.FPN(BACKBONE, classes=n_classes, \n",
    "#                input_shape=(volumn_size, patch_size, patch_size, channels), \n",
    "#                encoder_weights=encoder_weights,\n",
    "#                activation=activation,\n",
    "#                pyramid_dropout=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from segmentation_models_3D.utils import set_regularization\n",
    "'''\n",
    "    set_regularization(model,\n",
    "    kernel_regularizer=None,\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    beta_regularizer=None,\n",
    "    gamma_regularizer=None,\n",
    "    **kwargs)\n",
    "'''\n",
    "\n",
    "# l2=0.01 ioU=0.83\n",
    "# l2=0.1\n",
    "regularizer = tf.keras.regularizers.L2(l2=0.01)\n",
    "# regularizer = tf.keras.regularizers.L1(l1=0.01)\n",
    "set_regularization(model, kernel_regularizer = regularizer,\n",
    "                   bias_regularizer = regularizer)\n",
    "# set_regularization(model, activity_regularizer = regularizer) #ใช้ไม่ได้นะเวลา train ละจะ error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aliases\n",
    "# jaccard_loss = JaccardLoss()\n",
    "# dice_loss = DiceLoss()\n",
    "\n",
    "# binary_focal_loss = BinaryFocalLoss()\n",
    "# categorical_focal_loss = CategoricalFocalLoss()\n",
    "# binary_crossentropy = BinaryCELoss()\n",
    "# categorical_crossentropy = CategoricalCELoss()\n",
    "\n",
    "# loss combinations\n",
    "# categorical_focal_dice_loss = categorical_focal_loss + dice_loss ตอนนี้ใช้อันนี้อยู่\n",
    "# categorical_focal_jaccard_loss = categorical_focal_loss + jaccard_loss\n",
    "# cce_dice_loss = categorical_crossentropy + dice_loss\n",
    "# cce_jaccard_loss = categorical_crossentropy + jaccard_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dice_loss = DiceLoss()\n",
    "# categorical_focal_loss = CategoricalFocalLoss()\n",
    "# categorical_crossentropy = CategoricalCELoss()\n",
    "# categorical_focal_dice_loss = categorical_focal_loss + dice_loss ตอนนี้ใช้อันนี้อยู่\n",
    "# cce_dice_loss = categorical_crossentropy + dice_loss\n",
    "\n",
    "total_loss = sm.losses.categorical_focal_dice_loss\n",
    "model.compile(optimizer = optim, loss=total_loss, metrics=metrics)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize Model Struture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pydot\n",
    "# !pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.utils.vis_utils import plot_model\n",
    "# path_ = '/tf/Project/LungLobe/'\n",
    "# Model_name = '3DUNet_densenet121_Model1'\n",
    "# save_path_model_struture = path_+'LungModel/'+Model_name+'.png'\n",
    "\n",
    "# plot_model(model, to_file=save_path_model_struture, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit model Densenet121-3DUnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Densenet121-3DUnet, Densenet169-3DUnet #เทรนทุกสไลด์ Tiff_256x256\n",
    "# class:6 : 1 background+ 5 lobe\n",
    "# เทรน 200 Epochs โดยมี EarlyStopping\n",
    "import time\n",
    "import datetime\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10) #20\n",
    "\n",
    "path_ = '/tf/Project/LungLobe/'\n",
    "Model_name = '3DUNet_resnet152_Model46'\n",
    "save_path_ = path_+'LungModel/'+Model_name+'.h5'\n",
    "mc = ModelCheckpoint(save_path_, monitor='val_iou_score', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "start = time.time()\n",
    "#-------------------------------------------\n",
    "# train 24 val 8\n",
    "history=model.fit(X_train_prep, y_train, batch_size=1, \n",
    "          epochs=100, verbose=1,\n",
    "          validation_data=(X_test_prep, y_test),\n",
    "          shuffle=True,\n",
    "          callbacks=[es, mc])\n",
    "#-------------------------------------------\n",
    "end = time.time()\n",
    "print('time process used>', str(datetime.timedelta(seconds=end - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "save_model_p = path_+'LungModel/'+'History_'+Model_name\n",
    "with open(save_model_p, 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
